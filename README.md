# PackageRecDataset

This pacakage recommendations dataset is generated by randomly select 1,400 "top" and 600 "bottom" images from Amazon product data \cite{mcauley2015image, mcauley2015inferring} and obtaining  30 ratings each from 200 participants recruited from Amazon Mechanical Turk for individual tops and bottoms and packages combining them.

For each participant, we first asked them whether they wear clothes for men or women, and then provided 30 screens where each screen showed images of one top and one bottom filtered for their chosen gender preference. We also asked participants 
to rate on a scale of 1 to 5 how much: 
1. They would like to wear the top, 
2. They would like to wear the trousers,
3. They would like to wear the top and trousers together.

%An example can be seen in Figure \ref{fig:questionnaire}. 
From our participants, we obtained 12,000 individual ratings and 6,000 package ratings. The distribution of ratings for our data set are shown in Table \ref{tab:ratingDist}. Note that the percentage of highly rated packages is much lower than that of either tops or bottoms.

Given $r_{u,i^t}$ as a "top" rating, $r_{u,i^b}$ as a ``bottom'' rating and $r_{u,(i^t, i^b)}$ as ``package'' rating, there are six possibilities:
1. We do not know $r_{u,(i^t, i^b)}$, but we know $r_{u,i^t}$ or $r_{u,i^b}$;
2. We do not know $r_{u,(i^t, i^b)}$, but we know $r_{u,i^t}$ and $r_{u,i^b}$;
3. We know $r_{u,(i^t, i^b)}$, but we only know one of $r_{u,i^t}$ and $r_{u,i^b}$;
4. We know $r_{u,(i^t, i^b)}$, but do not know either $r_{u,i^t}$ or $r_{u,i^b}$;
5. We know $r_{u,i^t}$, $r_{u,i^b}$, and $r_{u,(i^t, i^b)}$.
6. We do not know $r_{u,i^t}$, $r_{u,i^b}$, or $r_{u,(i^t, i^b)}$.

Our dataset collected ratings for "top", "bottom" and "package" together; thus for any user only (5-6) are possible. However (1-4) are realistic scenarios for a package recommendation system.

To cover all these possibilities, we adopted the following methodology. First, we used 4-fold crossvalidation by randomly splitting the individual ratings into four parts. We rotated and used 3 parts as the training set and one for testing. Then in each fold we used only 25% of package ratings $r_{u,(i^t, i^b)}$ as the training set, and the remaining 75% package ratings $r_{u,(i^t, i^b)}$ as the test set. These mechanisms for holding  back data to make package predictions ensure that all possibilities are covered in a realistic manner.
